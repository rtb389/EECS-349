{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-7-7c9ab59ec5a8>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-7c9ab59ec5a8>\"\u001b[1;36m, line \u001b[1;32m43\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#Starter code for spam filter assignment in EECS349 Machine Learning\n",
    "#Author: Prem Seetharaman (replace your name here)\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def parse(text_file):\n",
    "\t#This function parses the text_file passed into it into a set of words. \n",
    "    #Right now it just splits up the file by blank spaces, and returns the set of unique strings used in the file. \n",
    "\tcontent = text_file.read()\n",
    "\treturn np.unique(content.split())\n",
    "\n",
    "def writedictionary(dictionary, dictionary_filename):\n",
    "\t#Don't edit this function. It writes the dictionary to an output file.\n",
    "\toutput = open(dictionary_filename, 'w')\n",
    "\theader = 'word\\tP[word|spam]\\tP[word|ham]\\n'\n",
    "\toutput.write(header)\n",
    "\tfor k in dictionary:\n",
    "\t\tline = '{0}\\t{1}\\t{2}\\n'.format(k, str(dictionary[k]['spam']), str(dictionary[k]['ham']))\n",
    "\t\toutput.write(line)\n",
    "\t\t\n",
    "\n",
    "def makedictionary(spam_directory, ham_directory, dictionary_filename):\n",
    "\t#Making the dictionary. \n",
    "\tspam = [f for f in os.listdir(spam_directory) if os.path.isfile(os.path.join(spam_directory, f))]\n",
    "\tham = [f for f in os.listdir(ham_directory) if os.path.isfile(os.path.join(ham_directory, f))]\n",
    "\t\n",
    "\tspam_prior_probability = len(spam)/float((len(spam) + len(ham)))\n",
    "\t\n",
    "\twords = {}\n",
    "\n",
    "\t#These for loops walk through the files and construct the dictionary. \n",
    "    #The dictionary, words, is constructed so that words[word]['spam'] gives the probability of observing that word, \n",
    "    #given we have a spam document P(word|spam), and words[word]['ham'] gives the probability of observing that word, \n",
    "    #given a hamd document P(word|ham). Right now, all it does is initialize both probabilities to 0. \n",
    "    #TODO: add code that puts in your estimates for P(word|spam) and P(word|ham).\n",
    "\tfor s in spam:\n",
    "\t\tfor word in parse(open(spam_directory + s)):\n",
    "\t\t\tif word not in words:\n",
    "\t\t\t\twords[word] = {'spam': 1, 'ham': 0}\n",
    "            else:\n",
    "                words[word]['spam']+=1\n",
    "\tfor h in ham:\n",
    "\t\tfor word in parse(open(ham_directory + h)):\n",
    "\t\t\tif word not in words:\n",
    "\t\t\t\twords[word] = {'spam': 0, 'ham': 1}\n",
    "            else:\n",
    "                words[word]['ham']+=1\n",
    "    \n",
    "    #Change word counts to probabilities/likelihoods/whatever you call them\n",
    "    for word in words:\n",
    "        words[word]['spam'] = float(words[word]['spam']+1)/(len(spam)+1)\n",
    "        words[word]['ham'] = float(words[word]['ham']+1)/(len(ham)+1)\n",
    "\t\n",
    "\t#Write it to a dictionary output file.\n",
    "\twritedictionary(words, dictionary_filename)\n",
    "\t\n",
    "\treturn words, spam_prior_probability\n",
    "\n",
    "def is_spam(content, dictionary, spam_prior_probability):\n",
    "\t#TODO: Update this function. Right now, all it does is checks whether the spam_prior_probability is more than half the data. \n",
    "    #If it is, it says spam for everything. Else, it says ham for everything. \n",
    "    #You need to update it to make it use the dictionary and the content of the mail. Here is where your naive Bayes classifier goes.\n",
    "    content = [word for word in content if word in dictionary]\n",
    "    prob_spam = 0\n",
    "    prob_ham = 0\n",
    "    for word in content:\n",
    "        prob_spam += np.log(dictionary[word]['spam'])\n",
    "        prob_ham += np.log(dictionary[word]['ham'])\n",
    "\tif np.log(spam_prior_probability)+prob_spam >= np.log(1-spam_prior_probability)+prob_ham:\n",
    "\t\treturn True\n",
    "\telse:\n",
    "\t\treturn False\n",
    "\n",
    "def spamsort(mail_directory, spam_directory, ham_directory, dictionary, spam_prior_probability):\n",
    "\tmail = [f for f in os.listdir(mail_directory) if os.path.isfile(os.path.join(mail_directory, f))]\n",
    "\tfor m in mail:\n",
    "\t\tcontent = parse(open(mail_directory + m))\n",
    "\t\tspam = is_spam(content, dictionary, spam_prior_probability)\n",
    "\t\tif spam:\n",
    "\t\t\tshutil.copy(mail_directory + m, spam_directory)\n",
    "\t\telse:\n",
    "\t\t\tshutil.copy(mail_directory + m, ham_directory)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\t#Here you can test your functions. Pass it a training_spam_directory, a training_ham_directory, \n",
    "    #and a mail_directory that is filled with unsorted mail on the command line. \n",
    "    #It will create two directories in the directory where this file exists: sorted_spam, and sorted_ham. \n",
    "    #The files will show up  in this directories according to the algorithm you developed.\n",
    "\ttraining_spam_directory = sys.argv[1]\n",
    "\ttraining_ham_directory = sys.argv[2]\n",
    "\t\n",
    "\ttest_mail_directory = sys.argv[3]\n",
    "\ttest_spam_directory = 'sorted_spam'\n",
    "\ttest_ham_directory = 'sorted_ham'\n",
    "\t\n",
    "\tif not os.path.exists(test_spam_directory):\n",
    "\t\tos.mkdir(test_spam_directory)\n",
    "\tif not os.path.exists(test_ham_directory):\n",
    "\t\tos.mkdir(test_ham_directory)\n",
    "\t\n",
    "\tdictionary_filename = \"dictionary.dict\"\n",
    "\t\n",
    "\t#create the dictionary to be used\n",
    "\tdictionary, spam_prior_probability = makedictionary(training_spam_directory, training_ham_directory, dictionary_filename)\n",
    "\t#sort the mail\n",
    "\tspamsort(test_mail_directory, test_spam_directory, test_ham_directory, dictionary, spam_prior_probability) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def parse(text_file):\n",
    "\t#This function parses the text_file passed into it into a set of words. \n",
    "    #Right now it just splits up the file by blank spaces, and returns the set of unique strings used in the file. \n",
    "\tcontent = text_file.read()\n",
    "\treturn np.unique(content.split())\n",
    "\n",
    "def writedictionary(dictionary, dictionary_filename):\n",
    "\t#Don't edit this function. It writes the dictionary to an output file.\n",
    "\toutput = open(dictionary_filename, 'w')\n",
    "\theader = 'word\\tP[word|spam]\\tP[word|ham]\\n'\n",
    "\toutput.write(header)\n",
    "\tfor k in dictionary:\n",
    "\t\tline = '{0}\\t{1}\\t{2}\\n'.format(k, str(dictionary[k]['spam']), str(dictionary[k]['ham']))\n",
    "\t\toutput.write(line)\n",
    "\t\t\n",
    "\n",
    "def makedictionary(spam_directory, ham_directory, dictionary_filename):\n",
    "\t#Making the dictionary. \n",
    "\tspam = [f for f in os.listdir(spam_directory) if os.path.isfile(os.path.join(spam_directory, f))]\n",
    "\tham = [f for f in os.listdir(ham_directory) if os.path.isfile(os.path.join(ham_directory, f))]\n",
    "\t\n",
    "\tspam_prior_probability = len(spam)/float((len(spam) + len(ham)))\n",
    "\t\n",
    "\twords = {}\n",
    "\n",
    "\t#These for loops walk through the files and construct the dictionary. \n",
    "    #The dictionary, words, is constructed so that words[word]['spam'] gives the probability of observing that word, \n",
    "    #given we have a spam document P(word|spam), and words[word]['ham'] gives the probability of observing that word, \n",
    "    #given a hamd document P(word|ham). Right now, all it does is initialize both probabilities to 0. \n",
    "    #TODO: add code that puts in your estimates for P(word|spam) and P(word|ham).\n",
    "\tfor s in spam:\n",
    "\t\tfor word in parse(open(spam_directory + s)):\n",
    "\t\t\tif word not in words:\n",
    "\t\t\t\twords[word] = {'spam': 1, 'ham': 0}\n",
    "\t\t\telse:\n",
    "\t\t\t\twords[word]['spam']+=1\n",
    "\tfor h in ham:\n",
    "\t\tfor word in parse(open(ham_directory + h)):\n",
    "\t\t\tif word not in words:\n",
    "\t\t\t\twords[word] = {'spam': 0, 'ham': 1}\n",
    "\t\t\telse:\n",
    "\t\t\t\twords[word]['ham']+=1\n",
    "    \n",
    "    #Change word counts to probabilities/likelihoods/whatever you call them\n",
    "\tfor word in words:\n",
    "\t\twords[word]['spam'] = float(words[word]['spam']+1)/(len(spam)+1)\n",
    "\t\twords[word]['ham'] = float(words[word]['ham']+1)/(len(ham)+1)\n",
    "\t\n",
    "\t#Write it to a dictionary output file.\n",
    "\twritedictionary(words, dictionary_filename)\n",
    "\t\n",
    "\treturn words, spam_prior_probability\n",
    "\n",
    "def is_spam(content, dictionary, spam_prior_probability):\n",
    "\t#TODO: Update this function. Right now, all it does is checks whether the spam_prior_probability is more than half the data. \n",
    "    #If it is, it says spam for everything. Else, it says ham for everything. \n",
    "    #You need to update it to make it use the dictionary and the content of the mail. Here is where your naive Bayes classifier goes.\n",
    "\tcontent = [word for word in content if word in dictionary]    \n",
    "\tprob_spam = 0\n",
    "\tprob_ham = 0\n",
    "\tfor word in content:\n",
    "\t\tprob_spam += np.log(dictionary[word]['spam'])\n",
    "\t\tprob_ham += np.log(dictionary[word]['ham'])\n",
    "\tif np.log(spam_prior_probability)+prob_spam >= np.log(1-spam_prior_probability)+prob_ham:\n",
    "\t\treturn True\n",
    "\telse:\n",
    "\t\treturn False\n",
    "\n",
    "def spamsort(mail_directory, spam_directory, ham_directory, dictionary, spam_prior_probability):\n",
    "\tmail = [f for f in os.listdir(mail_directory) if os.path.isfile(os.path.join(mail_directory, f))]\n",
    "\tfor m in mail:\n",
    "\t\tcontent = parse(open(mail_directory + m))\n",
    "\t\tspam = is_spam(content, dictionary, spam_prior_probability)\n",
    "\t\tif spam:\n",
    "\t\t\tshutil.copy(mail_directory + m, spam_directory)\n",
    "\t\telse:\n",
    "\t\t\tshutil.copy(mail_directory + m, ham_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "dic = {'spam':{'spam':0.6,'ham':0.4},'ham':{'spam':0.25,'ham':0.5}}\n",
    "#Boundary should be 0.4 for prior prob\n",
    "print is_spam(['spam'],dic,0.39)\n",
    "print is_spam(['spam'],dic,0.4)\n",
    "#Boundary should be 4/7\n",
    "print is_spam(['spam','ham'],dic,float(4)/7)\n",
    "print is_spam(['spam','ham'],dic,float(4)/7-0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_spam = 'bitbootcamp/spam/'\n",
    "training_ham = 'bitbootcamp/easy_ham/'\n",
    "dictionary_dir = 'bitbootcamp/spam_dicts/'\n",
    "test_spam = 'bitbootcamp/test_spam/'\n",
    "test_ham = 'bitbootcamp/test_ham/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dictionary, spam_prior_probability = makedictionary(training_spam, training_ham, dictionary_dir+'dictionary.dict')\n",
    "spamsort(training_ham, test_spam, test_ham, dictionary, spam_prior_probability) \n",
    "print time.time() - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spamsort(training_spam, test_spam, test_ham, dictionary, spam_prior_probability) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testmakedictionary(spam, ham):\n",
    "\t#Making the dictionary, passes the lists for cross-validation\n",
    "\t\n",
    "\tspam_prior_probability = len(spam)/float((len(spam) + len(ham)))\n",
    "\t\n",
    "\twords = {}\n",
    "    \n",
    "\t#These for loops walk through the files and construct the dictionary. \n",
    "    #The dictionary, words, is constructed so that words[word]['spam'] gives the probability of observing that word, \n",
    "    #given we have a spam document P(word|spam), and words[word]['ham'] gives the probability of observing that word, \n",
    "    #given a hamd document P(word|ham). Right now, all it does is initialize both probabilities to 0. \n",
    "    #TODO: add code that puts in your estimates for P(word|spam) and P(word|ham).\n",
    "\tfor s in spam:\n",
    "\t\tfor word in parse(open(training_spam + s)):\n",
    "\t\t\tif word not in words:\n",
    "\t\t\t\twords[word] = {'spam': 1, 'ham': 0}\n",
    "\t\t\telse:\n",
    "\t\t\t\twords[word]['spam']+=1\n",
    "\tfor h in ham:\n",
    "\t\tfor word in parse(open(training_ham + h)):\n",
    "\t\t\tif word not in words:\n",
    "\t\t\t\twords[word] = {'spam': 0, 'ham': 1}\n",
    "\t\t\telse:\n",
    "\t\t\t\twords[word]['ham']+=1\n",
    "    \n",
    "    #Change word counts to probabilities/likelihoods/whatever you call them\n",
    "\tfor word in words:\n",
    "\t\twords[word]['spam'] = float(words[word]['spam']+1)/(len(spam)+1)\n",
    "\t\twords[word]['ham'] = float(words[word]['ham']+1)/(len(ham)+1)\n",
    "\t\n",
    "\t\n",
    "\treturn words, spam_prior_probability\n",
    "\n",
    "###########################################################################################################    \n",
    "\n",
    "def testspamsort(test_spam, test_ham, dictionary, spam_prior_probability):\n",
    "\tTP = 0\n",
    "\tFP = 0\n",
    "\tTN = 0\n",
    "\tFN = 0\n",
    "\t\n",
    "\tfor m in test_spam:\n",
    "\t\tcontent = parse(open(training_spam + m))\n",
    "\t\tspam = is_spam(content, dictionary, spam_prior_probability)\n",
    "\t\tif spam:\n",
    "\t\t\tTP+=1\n",
    "\t\telse:\n",
    "\t\t\tFN+=1\n",
    "\tfor m in test_ham:\n",
    "\t\tcontent = parse(open(training_ham + m))\n",
    "\t\tspam = is_spam(content, dictionary, spam_prior_probability)\n",
    "\t\tif spam:\n",
    "\t\t\tFP+=1\n",
    "\t\telse:\n",
    "\t\t\tTN+=1\n",
    "\treturn [TP,FP,TN,FN]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "\n",
    "spam = [f for f in os.listdir(training_spam) if os.path.isfile(os.path.join(training_spam, f))]\n",
    "ham = [f for f in os.listdir(training_ham) if os.path.isfile(os.path.join(training_ham, f))]\n",
    "\n",
    "rd.shuffle(spam)\n",
    "rd.shuffle(ham)\n",
    "\n",
    "TP = []\n",
    "FP = []\n",
    "TN = []\n",
    "FN = []\n",
    "priors  = []\n",
    "#create the dictionary to be used\n",
    "for i in range(50):\n",
    "    train_spam = spam[:i*len(spam)/50]+spam[(i+1)*len(spam)/50:]\n",
    "    train_ham = ham[:i*len(ham)/50]+ham[(i+1)*len(ham)/50:]\n",
    "    test_spam = spam[i*len(spam)/50:(i+1)*len(spam)/50]\n",
    "    test_ham = ham[i*len(ham)/50:(i+1)*len(ham)/50]\n",
    "    \n",
    "    dictionary, spam_prior_probability = testmakedictionary(train_spam, train_ham)\n",
    "    #sort the mail\n",
    "    out = testspamsort(test_spam, test_ham, dictionary, spam_prior_probability) \n",
    "    TP.append(out[0])\n",
    "    FP.append(out[1])\n",
    "    TN.append(out[2])\n",
    "    FN.append(out[3])\n",
    "    priors.append(spam_prior_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50]\n",
      "[11, 12, 7, 12, 4, 2, 13, 11, 10, 2]\n",
      "[244, 243, 248, 243, 251, 253, 242, 244, 245, 254]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0.1638747268754552, 0.1638747268754552, 0.1638747268754552, 0.1638747268754552, 0.1638747268754552, 0.1638747268754552, 0.1638747268754552, 0.1638747268754552, 0.1638747268754552, 0.16393442622950818]\n"
     ]
    }
   ],
   "source": [
    "print TP\n",
    "print FP\n",
    "print TN\n",
    "print FN\n",
    "print priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average F1 score:  0.938968567664\n",
      "Average Accuracy Bayes:  0.977704918033\n",
      "Average Accuracy Prior:  0.836118455843\n"
     ]
    }
   ],
   "source": [
    "F1 = []\n",
    "Acc_Bayes = []\n",
    "Acc_Prior = []\n",
    "for i in range(50):\n",
    "    F1.append(float(2*TP[i])/(2*TP[i]+FN[i]+FP[i]))\n",
    "    Acc_Bayes.append(float(TP[i]+TN[i])/(TP[i]+TN[i]+FP[i]+FN[i]))\n",
    "    Acc_Prior.append(float(TN[i]+FP[i])/(TP[i]+TN[i]+FP[i]+FN[i]))\n",
    "    \n",
    "print 'Average F1 score: ', np.mean(F1)\n",
    "print 'Average Accuracy Bayes: ', np.mean(Acc_Bayes)\n",
    "print 'Average Accuracy Prior: ', np.mean(Acc_Prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
